{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of DLSS RL Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akk216/GeNWrK/blob/main/CH20B017_RL_Pytorch_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0LNqmFS049t"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nihalgeorge01/DLSS_RL/blob/main/DLSS_RL_Assignment.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqX8zONPzfGa"
      },
      "source": [
        "# Black Hole\n",
        "### This game is described using a 10 X 10 grid :\n",
        ">   \n",
        "\\_ \\_ \\_ \\_ \\_ \\_ \\_ \\_ \\_ H  \n",
        "\\_ \\_ \\_ \\_ \\_ \\_ \\_ H \\_ \\_  \n",
        "\\_ \\_ \\_ \\_ \\_ H \\_ \\_ \\_ \\_  \n",
        "\\_ \\_ \\_ H \\_ \\_ \\_ \\_ \\_ \\_  \n",
        "\\_ H \\_ \\_ \\_ \\_ \\_ \\_ \\_ \\_  \n",
        "\\_ \\_ \\_ \\_ \\_ \\_ \\_ \\_ \\_ H  \n",
        "\\_ \\_ \\_ \\_ \\_ \\_ \\_ H \\_ \\_  \n",
        "\\_ \\_ \\_ \\_ \\_ H \\_ \\_ \\_ \\_  \n",
        "\\_ \\_ \\_ H \\_ \\_ \\_ \\_ \\_ \\_  \n",
        "G H \\_ \\_ \\_ \\_ \\_ \\_ \\_ \\_  \n",
        "\n",
        "\\_ : Safe path  \n",
        "H : Black Hole, avoid falling  \n",
        "G: Goal, target to reach  \n",
        "\n",
        "Holes will continuously move 1 step left during each timestep.  \n",
        "Your goal is to reach G.  \n",
        "You fall into the hole only if your position coincides with the hole.  \n",
        "The episode ends when you reach G or fall in H.  \n",
        "If you reach G, you win.  \n",
        "If you reach H, you lose.  \n",
        "If you reach G at a time when it coincides with H, you lose.  \n",
        "## Reward Scheme \n",
        "- 1 if you reach G  \n",
        "- -1 if you fall in H  \n",
        "- 0 otherwise.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV64yW7Tl1Tj"
      },
      "source": [
        "# **DO NOT EDIT THE CELL BELOW**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42AI1ItvI_Ho"
      },
      "source": [
        "import random\n",
        "import sys\n",
        "import copy\n",
        "class BlackHole:\n",
        "  class action:\n",
        "    def __init__(self):\n",
        "      self.total_actions = 5\n",
        "      self.dtype = type(self.total_actions)\n",
        "      self.__out=sys.stdout\n",
        "    \n",
        "    def random_action(self):\n",
        "      act = random.randint(1,5)\n",
        "      return act\n",
        "\n",
        "    def show_actions(self):\n",
        "      actions= \"1->Up, 2->Right, 3->Down, 4->Left 5->Stay\"\n",
        "      self.__out.write(actions)\n",
        "    \n",
        "  class observation:\n",
        "    def __init__(self):\n",
        "      self.total_observations = 1000\n",
        "      self.dtype = type(self.total_observations)\n",
        "      self.__lst =[x for x in range(1,1000) if x%100 is not 0]\n",
        "\n",
        "    def random(self):\n",
        "      obs = random.sample(self.__lst,1)[0]\n",
        "      return obs\n",
        "  def __init__(self):\n",
        "    self.observation_space = self.observation()\n",
        "    self.__map=['_________H',\n",
        "                '_______H__',\n",
        "                '_____H____',\n",
        "                '___H______',\n",
        "                '_H________',\n",
        "                '_________H',\n",
        "                '_______H__',\n",
        "                '_____H____',\n",
        "                '___H______',\n",
        "                'GH________']\n",
        "    self.action_space = self.action()\n",
        "    self.__x = None\n",
        "    self.__y = None\n",
        "    self.__state = None\n",
        "    self.__out = sys.stdout\n",
        "    self.__action = None\n",
        "    self.__action_dict = {1:'Up',2:'Right',3:'Down',4:'Left',5:'Stay'}\n",
        "    self.__done = False\n",
        "    self.__h = None\n",
        "\n",
        "  def reset(self):\n",
        "    self.__y = 0\n",
        "    self.__h = 9\n",
        "    self.__adjust_h()\n",
        "    self.__x = random.randint(0,4)\n",
        "    self.current_state()\n",
        "    self.__action = None\n",
        "    self.__done = False\n",
        "    return self.__state\n",
        "\n",
        "  def __adjust_h(self):\n",
        "    for i in  range(len(self.__map)):\n",
        "      if i==9 and self.__map[i].count('_')==9:\n",
        "        self.__map[9] = self.__map[9][:9]\n",
        "      self.__map[i] = ''.join(i for i in self.__map[i] if i is not 'H')\n",
        "      index = self.__h-2*i \n",
        "      index  = index + (index<0 and index>-10)*10 + (index<-10)*20 \n",
        "      self.__map[i] = self.__map[i][:index] + 'H' + self.__map[i][index:]\n",
        "    if self.__h == 8:\n",
        "      self.__map[9] = ''.join(i for i in self.__map[9] if i is not 'H')+'_'\n",
        "  \n",
        "  def current_state(self):\n",
        "    if self.__y is not None:\n",
        "     self.__state = (9-self.__h)*100+self.__y*10+self.__x+1\n",
        "    return self.__state\n",
        "\n",
        "  def take_step(self,action):\n",
        "    if self.__done == False :\n",
        "      reward = 0.0\n",
        "      if action == 1:\n",
        "        if self.__y-1>=0:\n",
        "          self.__y-=1\n",
        "        self.__action = action\n",
        "      elif action == 3:\n",
        "        if self.__y+1<=9:\n",
        "          self.__y+=1\n",
        "        self.__action = action\n",
        "      elif action == 2:\n",
        "        if self.__x+1<=9:\n",
        "          self.__x+=1\n",
        "        self.__action = action\n",
        "      elif action == 4:\n",
        "        if self.__x-1>=0:\n",
        "          self.__x-=1\n",
        "        self.__action = action\n",
        "      elif action == 5:\n",
        "        self.__action = action\n",
        "      else:\n",
        "        self.__out.write(\"Enter a valid action.\")\n",
        "        return\n",
        "      self.__h  = self.__h -1 + (self.__h-1<0)*10\n",
        "      self.__adjust_h()\n",
        "      self.current_state()\n",
        "      if self.__map[self.__y][self.__x]=='G' :\n",
        "        reward=1.0\n",
        "        self.__done= True\n",
        "        if self.__h ==8:\n",
        "          reward = -1.0\n",
        "          self.__done = True\n",
        "      if self.__map[self.__y][self.__x]=='H':\n",
        "        reward = -1.0\n",
        "        self.__done = True\n",
        "      return self.__state,reward,self.__done\n",
        "    else :\n",
        "      self.__out.write(\"\\n\\033[38;5;11mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True\\033[0;0m\")\n",
        "\n",
        "  def show(self):\n",
        "    if self.__state is not None:\n",
        "      map = copy.deepcopy(self.__map)\n",
        "      val = map[self.__y][self.__x]\n",
        "      map[self.__y] = map[self.__y][:self.__x] + 'P' +map[self.__y][self.__x+1:]\n",
        "      map = self.__add_colour_h(map)\n",
        "      map[-1]=map[-1].replace('G',\"\\033[38;5;12mG\\033[0;0m\")\n",
        "      map[self.__y] = map[self.__y].replace('P',f'\\033[48;5;9m{val}\\033[0;0m')\n",
        "      if self.__action is not None:\n",
        "        self.__out.write('\\n'+self.__action_dict[self.__action])\n",
        "      self.__out.write(\"\\n+----------+\")\n",
        "      for i in map:\n",
        "        self.__out.write('\\n|'+i+'|')\n",
        "      self.__out.write(\"\\n+----------+\")\n",
        "      if val =='H':\n",
        "        self.__out.write(\"\\nTRY AGAIN.......You fell in Black Hole!!!\")\n",
        "      if val =='G':\n",
        "        if self.__h is not 8 : \n",
        "          self.__out.write(\"\\nGG!!\")\n",
        "        else :\n",
        "          self.__out.write(\"\\nYou reached but fell in Black Hole\")\n",
        "      self.__out.write(\"\\n\")\n",
        "    else :\n",
        "      self.__out.write('NONE')\n",
        "\n",
        "  def __add_colour_h(self,map):\n",
        "    for i in range(len(map)):\n",
        "      map[i]=map[i].replace('H','\\033[48;5;16mH\\033[0;0m')\n",
        "    if self.__h == 8:\n",
        "      map[9] = map[9].replace('G','\\033[48;5;16mG\\033[0;0m')\n",
        "    return map\n",
        "\n",
        "  def set_state(self,state):\n",
        "    if state>1000 or state<1:\n",
        "      self.__out.write(\"Enter a valid state.\")\n",
        "      return\n",
        "    self.__state = state\n",
        "    self.__h = 9 - (state-1)//100\n",
        "    self.__y = ((state-1)%100)//10\n",
        "    self.__x = ((state-1)%100)%10\n",
        "    self.__adjust_h()\n",
        "    if self.__map[self.__y][self.__x]=='_':\n",
        "      self.__done = False\n",
        "    else: \n",
        "      self.__done = True\n",
        "    self.__action = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj_sx_AH2Sum"
      },
      "source": [
        "# Environment methods and attributes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz4_-7xu2mL2"
      },
      "source": [
        "env = BlackHole() #Creating object of BlackHole class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ocX7o8B2tj1",
        "outputId": "a6432a58-1ea4-4cc3-bf40-1be2ee815591"
      },
      "source": [
        "print(env.observation_space.total_observations) #Total observations in observation space\n",
        "print(env.observation_space.random()) # Random observation from observation space"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "370\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE3kSOaN3tNr",
        "outputId": "5fc1337e-d2d1-4a82-fb60-bb4d13726e36"
      },
      "source": [
        "print(env.action_space.total_actions) #Total actions in action space\n",
        "print(env.action_space.random_action()) #Returns random action from action space\n",
        "env.action_space.show_actions() #Prints details about actions in action space"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "5\n",
            "1->Up, 2->Right, 3->Down, 4->Left 5->Stay"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mm8C4zO3uyg",
        "outputId": "dd374178-8ed4-465e-8fd6-6bc119844c71"
      },
      "source": [
        "print(env.current_state()) #No state is initialized"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkCeJnMS3xud",
        "outputId": "f5926708-ffd4-420b-dcad-a75009ecda07"
      },
      "source": [
        "env.reset() #initializes game and you are spawned at one of first five blocks\n",
        "env.show() #prints observation\n",
        "print(env.current_state())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "+----------+\n",
            "|___\u001b[48;5;9m_\u001b[0;0m_____\u001b[48;5;16mH\u001b[0;0m|\n",
            "|_______\u001b[48;5;16mH\u001b[0;0m__|\n",
            "|_____\u001b[48;5;16mH\u001b[0;0m____|\n",
            "|___\u001b[48;5;16mH\u001b[0;0m______|\n",
            "|_\u001b[48;5;16mH\u001b[0;0m________|\n",
            "|_________\u001b[48;5;16mH\u001b[0;0m|\n",
            "|_______\u001b[48;5;16mH\u001b[0;0m__|\n",
            "|_____\u001b[48;5;16mH\u001b[0;0m____|\n",
            "|___\u001b[48;5;16mH\u001b[0;0m______|\n",
            "|\u001b[38;5;12mG\u001b[0;0m\u001b[48;5;16mH\u001b[0;0m________|\n",
            "+----------+\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV1rFKPt45fL",
        "outputId": "d4211f56-5e5c-4a73-c1f7-e19c4e2e7765"
      },
      "source": [
        "env.set_state(env.observation_space.random()) #state of environment is changed to state specified\n",
        "env.show() \n",
        "print(env.current_state())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "+----------+\n",
            "|____\u001b[48;5;16mH\u001b[0;0m_____|\n",
            "|__\u001b[48;5;16mH\u001b[0;0m_______|\n",
            "|\u001b[48;5;16mH\u001b[0;0m_________|\n",
            "|________\u001b[48;5;16mH\u001b[0;0m_|\n",
            "|______\u001b[48;5;16mH\u001b[0;0m___|\n",
            "|____\u001b[48;5;16mH\u001b[0;0m_____|\n",
            "|__\u001b[48;5;16mH\u001b[0;0m_______|\n",
            "|\u001b[48;5;9mH\u001b[0;0m_________|\n",
            "|________\u001b[48;5;16mH\u001b[0;0m_|\n",
            "|\u001b[38;5;12mG\u001b[0;0m_____\u001b[48;5;16mH\u001b[0;0m___|\n",
            "+----------+\n",
            "TRY AGAIN.......You fell in Black Hole!!!\n",
            "571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6-bR6VW4IfZ"
      },
      "source": [
        "### env.take_step( ) returns THREE values only -- state, reward and done (episode completed or not) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTujgWrb4HS_",
        "outputId": "fb9d256d-c739-4ca2-f4af-ae4f3cdf7257"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from time import sleep\n",
        "env.reset()\n",
        "done = False\n",
        "while True:\n",
        "  env.show()\n",
        "  clear_output(wait=True)\n",
        "  sleep(1.0)\n",
        "  if done: \n",
        "    break\n",
        "  action = env.action_space.random_action()\n",
        "  state,reward,done = env.take_step(action)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Up\n",
            "+----------+\n",
            "|_\u001b[48;5;9mH\u001b[0;0m________|\n",
            "|_________\u001b[48;5;16mH\u001b[0;0m|\n",
            "|_______\u001b[48;5;16mH\u001b[0;0m__|\n",
            "|_____\u001b[48;5;16mH\u001b[0;0m____|\n",
            "|___\u001b[48;5;16mH\u001b[0;0m______|\n",
            "|_\u001b[48;5;16mH\u001b[0;0m________|\n",
            "|_________\u001b[48;5;16mH\u001b[0;0m|\n",
            "|_______\u001b[48;5;16mH\u001b[0;0m__|\n",
            "|_____\u001b[48;5;16mH\u001b[0;0m____|\n",
            "|\u001b[38;5;12mG\u001b[0;0m__\u001b[48;5;16mH\u001b[0;0m______|\n",
            "+----------+\n",
            "TRY AGAIN.......You fell in Black Hole!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohra4kBeYvhw"
      },
      "source": [
        "## **Task**\n",
        "### Now you are familiar with BlackHole environment. You have to implement Q-learning on this custom environment. Remember you are not allowed to do any changes in BlackHole class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBPsebR8oKR1"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "q_table = np.random.rand(env.observation_space.total_observations+1, env.action_space.total_actions)\n",
        "\n",
        "(alpha, gamma, episodes, epsilon) = (0.6, 0.9, 10000, 0.4)\n",
        "total_epochs =0\n",
        "total_penalty = 0\n",
        "illegal_episode =[]\n",
        "for i in range(episodes):\n",
        "  state = env.reset()\n",
        "  epochs = 0\n",
        "  penalty, reward_tot = 0, 0  \n",
        "  illegal =0\n",
        "  \n",
        "  done = False \n",
        "  while not done:\n",
        "    rand = random.uniform(0,1)\n",
        "    \n",
        "    if rand < epsilon:\n",
        "      action = env.action_space.random_action()\n",
        "    if rand >= epsilon:\n",
        "      action = np.argmax(q_table[state])\n",
        "      action +=1\n",
        "\n",
        "    new_state,reward,done = env.take_step(action)\n",
        "\n",
        "  #  if new_state == state:\n",
        "   #   penalty+=1\n",
        "    #if reward == -10:\n",
        "     # illegal+=1\n",
        "\n",
        "    epochs += 1\n",
        "    action -= 1\n",
        "    \n",
        "    #Q_cal = Reward + gamma*max{a}(Q(s',.))\n",
        "    #new_q = oldq + aplha(Q_cal - oldq) = (1-alpha)oldq + alpha(Q_cal)\n",
        "          \n",
        "\n",
        "    oldq = q_table[state, action]\n",
        "    new_state_max = np.max(q_table[new_state]) \n",
        "    newq = (1 - alpha) * oldq + alpha * (reward + gamma * new_state_max)\n",
        "    q_table[state, action] = newq\n",
        "    state = new_state\n",
        "    \n",
        "    epochs+=1\n",
        "    \n",
        "  illegal_episode.append(illegal)\n",
        "  total_penalty+=penalty\n",
        "  total_epochs+=epochs\n",
        "  \n",
        "\n",
        "total_penalty/=episodes\n",
        "total_epochs/=episodes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyIf5zaAupDr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2902abe9-f632-4a69-cb2c-4f5f3f4b788a"
      },
      "source": [
        "state = env.reset()\n",
        "epochs = 0\n",
        "penalty, reward = 0, 0  \n",
        "done = False\n",
        "while True:\n",
        "  env.show()\n",
        "  clear_output(wait=True)\n",
        "  sleep(1.0)\n",
        "  epochs += 1\n",
        "  if done:\n",
        "    break\n",
        "  action = np.argmax(q_table[state])\n",
        "  new_state, reward, done= env.take_step(action+1)\n",
        "  \n",
        "print(\"Timesteps taken: {}\".format(epochs))\n",
        "print(\"Penalties incurred: {}\".format(penalty))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Timesteps taken: 10\n",
            "Penalties incurred: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STmBBvawm4_U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}