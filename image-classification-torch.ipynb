{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from PIL import Image\nfrom torch.utils.data import Dataset\nimport os\nfrom glob import glob\nimport torch\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nimport os\nimport time\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchsummary import summary\n\n\n# Dataset Class for Setting up the data loading process\n# Stuff to fill in this script: _init_transform()\nclass inaturalist(Dataset):\n    def __init__(self, root_dir, mode='train', transform=True):\n        self.data_dir = root_dir\n        self.mode = mode\n        self.transforms = transform\n        self._init_dataset()\n        if transform:\n            self._init_transform()\n\n    def _init_dataset(self):\n        self.files = []\n        self.labels = []\n        dirs = sorted(os.listdir(os.path.join(self.data_dir, 'train')))\n        if self.mode == 'train':\n            for dir in range(len(dirs)):\n                files = sorted(glob(os.path.join(self.data_dir, 'train', dirs[dir], '*.jpg')))\n                self.labels += [dir] * len(files)\n                self.files += files\n        elif self.mode == 'val':\n            for dir in range(len(dirs)):\n                files = sorted(glob(os.path.join(self.data_dir, 'val', dirs[dir], '*.jpg')))\n                self.labels += [dir] * len(files)\n                self.files += files\n        else:\n            print(\"No Such Dataset Mode\")\n            return None\n\n    def _init_transform(self):\n        self.transform = transforms.Compose([\n            transforms.CenterCrop(32),\n            transforms.ToTensor(),\n        ])\n\n    def __getitem__(self, index):\n        img = Image.open(self.files[index]).convert('RGB')\n        label = self.labels[index]\n\n        if self.transforms:\n            img = self.transform(img)\n\n        label = torch.tensor(label, dtype=torch.long)\n\n        return img, label\n\n    def __len__(self):\n        return len(self.files)\n    \n\nimport torch\n\n\n#Class to define the model which we will use for training\n#Stuff to fill in: The Architecture of your model, the forward function to define the forward pass\n# NOTE!: You are NOT allowed to use pretrained models for this task\n\nclass Classifier(nn.Module):\n    def __init__(self, n_classes):\n        super(Classifier, self).__init__()\n        self.network = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),  # output: 64 x 16 x 16\n\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),  # output: 128 x 8 x 8\n\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),  # output: 256 x 4 x 4\n\n            nn.Flatten(),\n            nn.Linear(256 * 4 * 4, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Linear(512, n_classes))\n\n    def forward(self, x):\n        \n        return self.network(x)\n\n   \n\n\n\n\n# Sections to Fill: Define Loss function, optimizer and model, Train and Eval functions and the training loop\n\n############################################# DEFINE HYPERPARAMS #####################################################\n# Feel free to change these hyperparams based on your machine's capactiy\nbatch_size = 5\nepochs = 5\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n############################################# DEFINE DATALOADER #####################################################\ntrainset = inaturalist(root_dir='../input/nature-12k/inaturalist_12K', mode='train')\nvalset = inaturalist(root_dir='../input/nature-12k/inaturalist_12K', mode='val')\ntrain_set=[]\n\nfor i in range(10):\n    for j in range(100):\n        k=(1000*i)+j\n        train_set.append(trainset[k])\n\n\ntrainloader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4)\nvalloader = DataLoader(valset, batch_size=1, shuffle=False, num_workers=4)\n\n################################### DEFINE LOSS FUNCTION, MODEL AND OPTIMIZER ######################################\ncriterion = nn.CrossEntropyLoss()\n\nmodel = Classifier(n_classes=10)\n\noptimize = optim.Adam\n\n\n################################### CREATE CHECKPOINT DIRECTORY ####################################################\n\n# NOTE: If you are using Kaggle to train this, remove this section. Kaggle doesn't allow creating new directories.\n#checkpoint_dir = 'checkpoints'\n#if not os.path.isdir(checkpoint_dir):\n #   os.makedirs(checkpoint_dir)\n\n\n#################################### HELPER FUNCTIONS ##############################################################\n\ndef get_model_summary(model, input_tensor_shape):\n    summary(model, input_tensor_shape)\n    \n\ndef accuracy(y_pred, y):\n    _, predicted = torch.max(y_pred.data, 1)\n    total = y.size(0)\n    correct = (predicted == y).sum().item()\n    return correct / total\n\n\ndef train(model, dataset, optimizer, criterion, device):\n    '''\n    Write the function to train the model for one epoch\n    Feel free to use the accuracy function defined above as an extra metric to track\n    '''\n    s=0\n    tot_loss=0\n    tot_metric=0\n    for xb,yb in dataset:\n        xb=xb.to(device)\n        yb=yb.to(device)\n        pred=model(xb)\n     \n        loss=F.cross_entropy(pred, yb)\n        s+=len(xb)\n        tot_loss+=(loss*len(xb))\n        acc=accuracy(pred, yb)\n        tot_metric+=(acc*len(xb))\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n        \n    return tot_loss,tot_metric,s\n   \n\n\ndef evalu(model, dataset, criterion, device):\n    '''\n    Write the function to validate the model after each epoch\n    Feel free to use the accuracy function defined above as an extra metric to track\n    '''\n    with torch.no_grad():\n        s=[]\n        tot_loss=[]\n        tot_metric=[]\n        for xb,yb in dataset:\n                xb=xb.to(device)\n                yb=yb.to(device)\n                pred=model(xb)\n                loss=criterion(pred, yb)\n                s+=len(xb)\n                tot_loss+=(loss*len(xb))\n                acc=accuracy(pred, yb)\n                tot_metric+=(acc*len(xb))\n                torch.cuda.empty_cache()\n        return tot_loss,tot_metric,s\n\n\n\n\n\n\ndef epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs\n\n\n################################################### TRAINING #######################################################\n# Get model Summary\nmodel=model.to(device, non_blocking=True);\n#get_model_summary(model, (3, 256, 256))\n\n# Training and Validation\nbest_valid_loss = float('inf')\ndef fit(learning_rate):\n  \n   \n    op=optimize(model.parameters(),learning_rate)\n    for epoch in range(epochs):\n        start_time = time.monotonic()\n        \n        \n        '''\n        Insert code to train and evaluate the model (Hint: use the functions you previously made :P)\n        Also save the weights of the model in the checkpoint directory\n        '''\n        tloss,tacc,ts=train(model, trainloader,op,criterion, device )\n        print(\"loss:\",(tloss/ts),\"Accuracy:\",(tacc/ts))\n        \n        #t1loss,t1acc,t1s=evalu(model,valloader,loss_func,device)\n        #print(\"loss:\",(t1loss/t1s),\"accuracy:\",(t1acc/t1s))\n\n\n        \nprint(\"OVERALL TRAINING COMPLETE\")\n   \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install torchsummary","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 0.0001\nfor i in range(10):\n    print(i)\n    fit(learning_rate)\nprint(\"comp\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}